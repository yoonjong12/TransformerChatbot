{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoonjong12/TransformerChatbot/blob/master/Train_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wQtVH7heCBM",
        "colab_type": "text"
      },
      "source": [
        "# Transformer Korean Chatbot\n",
        "트랜스포머(Transformer)를 활용한 한국어 챗봇입니다.\n",
        "* 학습 데이터는 '9회 투빅스 컨퍼런스 - 장애인의 용이한 정보접근을 위한 챗봇'을 준비하면서 수집한 장애인 관련 말뭉치들입니다.\\\n",
        "이 데이터는 저 혼자 전처리하고 수집한 것이 아니기 때문에 독단으로 공개하기 어려울 것 같습니다.\\\n",
        "다만, Test_Transformer.ipynb에서 챗봇을 직접 구동해보실 수 있습니다.\n",
        "\n",
        "* 이 Colab 노트북 파일은 어떻게 트랜스포머 모델을 tensorflow2.0 프레임워크에 맞추어 학습을 시키면 되는지 pipeline을 보여드리고자 준비했습니다.\n",
        "\n",
        "* 만약 Colab이 아닌 로컬에서 사용하고 싶으시다면 Colab에만 쓰이는 코드는 제외하시기 바랍니다.(명시는 해놓았으니 코드를 따라가주세요)\n",
        "\n",
        "* 트랜스포머 모듈의 자세한 설명은 module > Transformer.py에 주석으로 했습니다. 참고해주세요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLA2RldIrzHF",
        "colab_type": "code",
        "outputId": "f065e6d2-09f8-4525-c49f-36810865fb0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Colab과 개인 Gdrive를 연동하기 위한 코드입니다.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8pCao_QrqKp",
        "colab_type": "code",
        "outputId": "a2df90f2-bcd6-4115-8646-f612b35fd849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Tensorflow2.0 환경을 Colab에서 사용하기 위한 코드입니다.\n",
        "try:\n",
        "  # The %tensorflow_version magic only works in colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception as err:\n",
        "    print(str(err))\n",
        "    pass\n",
        "\n",
        "# import library\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import text\n",
        "from keras import metrics\n",
        "from keras import backend\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "# GPU로 학습을 시키기\n",
        "# GPU를 사용하기 위하여 Colab의 런타임 메뉴 > 런타임 유형 변경 > 하드웨어 가속기 에서 GPU로 설정하시기 바랍니다.  \n",
        "device = tf.test.gpu_device_name()\n",
        "if device != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "print(f'GPU at : {device}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU at : /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlTenHQMs4v8",
        "colab_type": "code",
        "outputId": "877d05e1-a362-40fa-b46e-e8b295e635cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/yoonjong12/TransformerChatbot.git\n",
        "\n",
        "# 깃허브로 클론한 모듈을 임포트합니다\n",
        "from TransformerChatbot.module.Transformer import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'TransformerChatbot' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujwJGNy7SXG_",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading & Preprocessing\n",
        "* 탄시리팀의 말뭉치를 로드하고 전처리합니다.\n",
        "* Preprocess클래스는 제가 직접 구현하였으며, 간단하게 올바른 인자만 넣어주면 학습 준비를 쉽게 할 수 있습니다.\n",
        "* 만약 데이터 배포가 가능해지거나, 다른 좋은 말뭉치가 있다면 수정하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCftAu5TpTt3",
        "colab_type": "code",
        "outputId": "da2c658f-48f9-469a-a389-a7d937fa2faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "# Corpus \n",
        "corpus = '/content/drive/My Drive/corpus_data.pickle'\n",
        "df = pd.read_pickle(corpus)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>pre_Question</th>\n",
              "      <th>pre_Answer</th>\n",
              "      <th>Q_token</th>\n",
              "      <th>A_token</th>\n",
              "      <th>len_Q_token</th>\n",
              "      <th>len_A_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>중증장애아동수당을 받는 중증장애인이 만21세가 된 경우 장애인연금을 별도로 신청해야...</td>\n",
              "      <td>중증장애아동수당을 받는 중증장애인이 초중등교육법 제2조에 따른 학교에 재학중인 경우...</td>\n",
              "      <td>중증장애아동수당을 받는 중증장애인이 만21세가 된 경우 장애인연금을 별도로 신청해야...</td>\n",
              "      <td>중증장애아동수당을 받는 중증장애인이 초중등교육법 제2조에 따른 학교에 재학중인 경우...</td>\n",
              "      <td>[중증, 장애, 아, 동, 수당, 을, 받는, 중, 증장, 애인, 이, 만, 21,...</td>\n",
              "      <td>[중증, 장애, 아, 동, 수당, 을, 받는, 중, 증장, 애인, 이, 초, 중등교...</td>\n",
              "      <td>25</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>장애인활동지원 교육기관과 제공기관에 대한 정보는 어디에서 확인할 수 있나요?</td>\n",
              "      <td>장애인활동지원 홈페이지(www.ableservice.or.kr)에서 지정된 활동 지...</td>\n",
              "      <td>장애인활동지원 교육기관과 제공기관에 대한 정보는 어디에서 확인할 수 있나요</td>\n",
              "      <td>장애인활동지원 홈페이지wwwableserviceorkr에서 지정된 활동 지원기관 및...</td>\n",
              "      <td>[장애인, 활동, 지원, 교육, 기관, 과, 제, 공, 기관, 에, 대한, 정보, ...</td>\n",
              "      <td>[장애인, 활동, 지원, 홈페이지, wwwableserviceorkr, 에서, 지정...</td>\n",
              "      <td>19</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>기초연금 수급권을 포기하면 장애인연금 기초급여를 받을 수 있나요?</td>\n",
              "      <td>장애인연금법 제6조 제5항에 따라 기초연금 수급권자에게는 기초급여를 지급하지 않습니다.</td>\n",
              "      <td>기초연금 수급권을 포기하면 장애인연금 기초급여를 받을 수 있나요</td>\n",
              "      <td>장애인연금법 제6조 제5항에 따라 기초연금 수급권자에게는 기초급여를 지급하지 않습니다</td>\n",
              "      <td>[기초, 연금, 수급, 권, 을, 포기, 하면, 장애인, 연금, 기초, 급여, 를,...</td>\n",
              "      <td>[장애인, 연금, 법, 제, 6조, 제, 5, 항, 에, 따라, 기초, 연금, 수급...</td>\n",
              "      <td>15</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>만19세 중증장애인이 2월에 학교를 졸업하고 장애인연금을 신청하면 2월부터 연금을 ...</td>\n",
              "      <td>장애인연금법에 따라 2월 중에는 장애인연금을 신청할 수 없으며, 미리 신청하더라도 ...</td>\n",
              "      <td>만19세 중증장애인이 2월에 학교를 졸업하고 장애인연금을 신청하면 2월부터 연금을 ...</td>\n",
              "      <td>장애인연금법에 따라 2월 중에는 장애인연금을 신청할 수 없으며 미리 신청하더라도 3...</td>\n",
              "      <td>[만, 19, 세, 중, 증장, 애인, 이, 2월, 에, 학교, 를, 졸업, 하고,...</td>\n",
              "      <td>[장애인, 연금, 법, 에, 따라, 2월, 중, 에는, 장애인, 연금, 을, 신청,...</td>\n",
              "      <td>25</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>장애인연금은 누가 받을 수 있나요?</td>\n",
              "      <td>만18세 이상의 등록 장애인 중 장애인연금법 상 중증장애인(종전 1, 2급 및 3급...</td>\n",
              "      <td>장애인연금은 누가 받을 수 있나요</td>\n",
              "      <td>만18세 이상의 등록 장애인 중 장애인연금법 상 중증장애인종전 1 2급 및 3급 중...</td>\n",
              "      <td>[장애인, 연금, 은, 누가, 받을, 수, 있나요]</td>\n",
              "      <td>[만, 18, 세, 이상, 의, 등록, 장애인, 중, 장애인, 연금, 법, 상, 중...</td>\n",
              "      <td>7</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question  ... len_A_token\n",
              "0  중증장애아동수당을 받는 중증장애인이 만21세가 된 경우 장애인연금을 별도로 신청해야...  ...          65\n",
              "1         장애인활동지원 교육기관과 제공기관에 대한 정보는 어디에서 확인할 수 있나요?  ...          21\n",
              "2               기초연금 수급권을 포기하면 장애인연금 기초급여를 받을 수 있나요?  ...          22\n",
              "3  만19세 중증장애인이 2월에 학교를 졸업하고 장애인연금을 신청하면 2월부터 연금을 ...  ...          24\n",
              "4                                장애인연금은 누가 받을 수 있나요?  ...          32\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7qweWwc9URI",
        "colab_type": "code",
        "outputId": "4267c87a-aed1-492a-d06e-c35c969f49b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "questions = df['Q_token']\n",
        "answers = df['A_token']\n",
        "MAX_LENGTH = 30\n",
        "preprocess = Preprocess()\n",
        "\n",
        "# 옵션1) 새로운 토크나이저 만들기\n",
        "tokenizer = preprocess.buildTokenizer(questions, answers)\n",
        "questions_seq, answers_seq = preprocess.tokenize_and_filter(tokenizer, MAX_LENGTH)\n",
        "# 토크나이저를 load또는 save하기 위한 주소\n",
        "tk_dir = '/content/drive/My Drive/tokenizer_data.json'\n",
        "# 옵션2) 토크나이저 저장\n",
        "preprocess.saveTokenizer(tk_dir, tokenizer)\n",
        "# 옵션3) 기존 토크나이저 로드\n",
        "# tokenizer = preprocess.loadTokenzier(tk_dir)\n",
        "# preprocess.questions = questions\n",
        "# preprocess.answers = answers\n",
        "# questions_seq, answers_seq = preprocess.tokenize_and_filter(tokenizer, MAX_LENGTH)\n",
        "\n",
        "print('Vocab size: {}'.format(preprocess.VOCAB_SIZE))\n",
        "print('Number of samples: {}'.format(len(questions_seq)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 57966\n",
            "Number of samples: 1570\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wJdVy7XulUm",
        "colab_type": "code",
        "outputId": "dfb9f32b-151a-4ab6-8266-0483ca52b865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# dataset\n",
        "# 입력 데이터와 출력 데이터, 배치사이즈만 인자로 넣어주면 자동으로 dataset을 만드는 함수입니다.\n",
        "# Tensorflow의 dataset은 batch train을 용이하게 해줍니다.\n",
        "BATCH_SIZE = 32\n",
        "dataset = preprocess.buildDataset(questions_seq, answers_seq, BATCH_SIZE)\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ({inputs: (None, 30), dec_inputs: (None, 29)}, {outputs: (None, 29)}), types: ({inputs: tf.int32, dec_inputs: tf.int32}, {outputs: tf.int32})>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3Fim0VLaNzJ",
        "colab_type": "text"
      },
      "source": [
        "# Train\n",
        "* 파라미터는 Transformer 논문과 일부 다를 수 있습니다.\n",
        "* github에 업로드하기 위해서는 100mb 미만이여야 하기때문에 모델 파라미터 크기를 많이 낮추었습니다.\n",
        "1. 각 파라미터를 설정해줍니다. \n",
        "2. model이 학습할 Transformer 모델입니다. 인자로 파라미터를 넣어주었습니다.\n",
        "3. 학습률과 옵티마이저를 설정하고 compile로 학습할 준비를 마칩니다.\n",
        "4. fit으로 학습을 시작합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0wbuhq3t75K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# parameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 32\n",
        "NUM_HEADS = 4\n",
        "UNITS = 64\n",
        "DROPOUT = 0.2\n",
        "VOCAB_SIZE = preprocess.VOCAB_SIZE\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=customLoss(MAX_LENGTH), metrics=[custom_accuracy(MAX_LENGTH)])\n",
        "\n",
        "# 옵션1) 재학습을 위한 모델 로드\n",
        "# MAX_LENGTH = 30\n",
        "# custom_objects = {'PositionalEncoding':PositionalEncoding,\n",
        "#                   'MultiHeadAttention':MultiHeadAttention,\n",
        "#                   'CustomSchedule':CustomSchedule,\n",
        "#                   'loss_function':customLoss(MAX_LENGTH),\n",
        "#                   'accuracy':custom_accuracy(MAX_LENGTH), \n",
        "#                   'create_padding_mask':create_padding_mask,\n",
        "#                   'backend':backend, \n",
        "#                   'tf':tf}\n",
        "# model = keras.models.load_model(path, custom_objects=custom_objects)\n",
        "\n",
        "# 옵션2) 모델 plot 시각화와 저장\n",
        "# tf.keras.utils.plot_model(model, to_file='transformer.png', show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIXh1-qzuc1M",
        "colab_type": "code",
        "outputId": "47cfef34-0d86-428e-b993-1dce035cd18b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "steps = len(questions_seq) // BATCH_SIZE\n",
        "EPOCHS = 150\n",
        "print(f'MAX_LENGTH : {MAX_LENGTH}, EPOCHS : {EPOCHS}')\n",
        "model.fit(dataset, epochs=EPOCHS, steps_per_epoch=steps)\n",
        "\n",
        "# 옵션) verbose = 0 모드일 떄 최종 train acc 찍어보는 거\n",
        "# test_scores = model.evaluate(dataset, verbose=2)\n",
        "# print('Test loss:', test_scores[0])\n",
        "# print('Test accuracy:', test_scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAX_LENGTH : 30, EPOCHS : 150\n",
            "Train for 49 steps\n",
            "Epoch 1/150\n",
            "49/49 [==============================] - 6s 122ms/step - loss: 6.5835 - accuracy: 4.3983e-05\n",
            "Epoch 2/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 6.5841 - accuracy: 0.0012\n",
            "Epoch 3/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 6.4192 - accuracy: 0.0054\n",
            "Epoch 4/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 6.2089 - accuracy: 0.0128\n",
            "Epoch 5/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 5.9902 - accuracy: 0.0203\n",
            "Epoch 6/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 5.8755 - accuracy: 0.0265\n",
            "Epoch 7/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 5.4759 - accuracy: 0.0326\n",
            "Epoch 8/150\n",
            "49/49 [==============================] - 6s 122ms/step - loss: 5.1412 - accuracy: 0.0344\n",
            "Epoch 9/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 4.8436 - accuracy: 0.0345\n",
            "Epoch 10/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 4.6959 - accuracy: 0.0345\n",
            "Epoch 11/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 4.4153 - accuracy: 0.0345\n",
            "Epoch 12/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 4.2050 - accuracy: 0.0345\n",
            "Epoch 13/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 4.1299 - accuracy: 0.0345\n",
            "Epoch 14/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 4.1575 - accuracy: 0.0345\n",
            "Epoch 15/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 4.0764 - accuracy: 0.0345\n",
            "Epoch 16/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 4.0378 - accuracy: 0.0345\n",
            "Epoch 17/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 4.0543 - accuracy: 0.0403\n",
            "Epoch 18/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 3.9871 - accuracy: 0.0446\n",
            "Epoch 19/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 4.0513 - accuracy: 0.0462\n",
            "Epoch 20/150\n",
            "49/49 [==============================] - 6s 122ms/step - loss: 3.9976 - accuracy: 0.0467\n",
            "Epoch 21/150\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 3.9653 - accuracy: 0.0462\n",
            "Epoch 22/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 3.8084 - accuracy: 0.0463\n",
            "Epoch 23/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 3.9397 - accuracy: 0.0482\n",
            "Epoch 24/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 3.9140 - accuracy: 0.0487\n",
            "Epoch 25/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 3.8610 - accuracy: 0.0500\n",
            "Epoch 26/150\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 3.7522 - accuracy: 0.0495\n",
            "Epoch 27/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 3.8160 - accuracy: 0.0505\n",
            "Epoch 28/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 3.7679 - accuracy: 0.0512\n",
            "Epoch 29/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 3.6565 - accuracy: 0.0529\n",
            "Epoch 30/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 3.5977 - accuracy: 0.0531\n",
            "Epoch 31/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 3.6381 - accuracy: 0.0539\n",
            "Epoch 32/150\n",
            "49/49 [==============================] - 6s 119ms/step - loss: 3.5545 - accuracy: 0.0544\n",
            "Epoch 33/150\n",
            "49/49 [==============================] - 6s 118ms/step - loss: 3.5792 - accuracy: 0.0556\n",
            "Epoch 34/150\n",
            "49/49 [==============================] - 6s 119ms/step - loss: 3.5479 - accuracy: 0.0559\n",
            "Epoch 35/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 3.5277 - accuracy: 0.0585\n",
            "Epoch 36/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 3.4731 - accuracy: 0.0599\n",
            "Epoch 37/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 3.3687 - accuracy: 0.0599\n",
            "Epoch 38/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 3.3545 - accuracy: 0.0630\n",
            "Epoch 39/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 3.3256 - accuracy: 0.0619\n",
            "Epoch 40/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 3.2479 - accuracy: 0.0673\n",
            "Epoch 41/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 3.1535 - accuracy: 0.0660\n",
            "Epoch 42/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 3.1521 - accuracy: 0.0698\n",
            "Epoch 43/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 3.0662 - accuracy: 0.0705\n",
            "Epoch 44/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 3.0164 - accuracy: 0.0732\n",
            "Epoch 45/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 3.0094 - accuracy: 0.0791\n",
            "Epoch 46/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.9979 - accuracy: 0.0819\n",
            "Epoch 47/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.9123 - accuracy: 0.0821\n",
            "Epoch 48/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.8902 - accuracy: 0.0894\n",
            "Epoch 49/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.8447 - accuracy: 0.0951\n",
            "Epoch 50/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.7874 - accuracy: 0.0944\n",
            "Epoch 51/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.6999 - accuracy: 0.0956\n",
            "Epoch 52/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.6804 - accuracy: 0.1026\n",
            "Epoch 53/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.5867 - accuracy: 0.1094\n",
            "Epoch 54/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.5842 - accuracy: 0.1140\n",
            "Epoch 55/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.5161 - accuracy: 0.1175\n",
            "Epoch 56/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.4683 - accuracy: 0.1244\n",
            "Epoch 57/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.4843 - accuracy: 0.1293\n",
            "Epoch 58/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.3619 - accuracy: 0.1336\n",
            "Epoch 59/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 2.3462 - accuracy: 0.1383\n",
            "Epoch 60/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 2.3153 - accuracy: 0.1447\n",
            "Epoch 61/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.2542 - accuracy: 0.1515\n",
            "Epoch 62/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.2348 - accuracy: 0.1599\n",
            "Epoch 63/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.1936 - accuracy: 0.1601\n",
            "Epoch 64/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.1331 - accuracy: 0.1683\n",
            "Epoch 65/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.1071 - accuracy: 0.1738\n",
            "Epoch 66/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.0465 - accuracy: 0.1729\n",
            "Epoch 67/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.0062 - accuracy: 0.1824\n",
            "Epoch 68/150\n",
            "49/49 [==============================] - 6s 119ms/step - loss: 2.0252 - accuracy: 0.1862\n",
            "Epoch 69/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 2.0008 - accuracy: 0.1875\n",
            "Epoch 70/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.9511 - accuracy: 0.1911\n",
            "Epoch 71/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.8756 - accuracy: 0.1916\n",
            "Epoch 72/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.9224 - accuracy: 0.1957\n",
            "Epoch 73/150\n",
            "49/49 [==============================] - 6s 122ms/step - loss: 1.8774 - accuracy: 0.2021\n",
            "Epoch 74/150\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 1.8385 - accuracy: 0.1947\n",
            "Epoch 75/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.8350 - accuracy: 0.2023\n",
            "Epoch 76/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.7702 - accuracy: 0.2091\n",
            "Epoch 77/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.7644 - accuracy: 0.2105\n",
            "Epoch 78/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.7379 - accuracy: 0.2105\n",
            "Epoch 79/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.7472 - accuracy: 0.2077\n",
            "Epoch 80/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.7601 - accuracy: 0.2145\n",
            "Epoch 81/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.6999 - accuracy: 0.2191\n",
            "Epoch 82/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.7062 - accuracy: 0.2246\n",
            "Epoch 83/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.6755 - accuracy: 0.2249\n",
            "Epoch 84/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.6720 - accuracy: 0.2201\n",
            "Epoch 85/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.6318 - accuracy: 0.2216\n",
            "Epoch 86/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.6217 - accuracy: 0.2294\n",
            "Epoch 87/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.6918 - accuracy: 0.2321\n",
            "Epoch 88/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.6476 - accuracy: 0.2327\n",
            "Epoch 89/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.6394 - accuracy: 0.2324\n",
            "Epoch 90/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.5648 - accuracy: 0.2344\n",
            "Epoch 91/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.6008 - accuracy: 0.2355\n",
            "Epoch 92/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.5798 - accuracy: 0.2378\n",
            "Epoch 93/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.5271 - accuracy: 0.2353\n",
            "Epoch 94/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.5468 - accuracy: 0.2400\n",
            "Epoch 95/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.5325 - accuracy: 0.2425\n",
            "Epoch 96/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.5794 - accuracy: 0.2516\n",
            "Epoch 97/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.4945 - accuracy: 0.2456\n",
            "Epoch 98/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.5076 - accuracy: 0.2537\n",
            "Epoch 99/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.4674 - accuracy: 0.2513\n",
            "Epoch 100/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.4591 - accuracy: 0.2551\n",
            "Epoch 101/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.4856 - accuracy: 0.2505\n",
            "Epoch 102/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.4593 - accuracy: 0.2548\n",
            "Epoch 103/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.4539 - accuracy: 0.2502\n",
            "Epoch 104/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.4325 - accuracy: 0.2616\n",
            "Epoch 105/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.4407 - accuracy: 0.2565\n",
            "Epoch 106/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.3670 - accuracy: 0.2606\n",
            "Epoch 107/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.4395 - accuracy: 0.2613\n",
            "Epoch 108/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.4303 - accuracy: 0.2638\n",
            "Epoch 109/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.4373 - accuracy: 0.2594\n",
            "Epoch 110/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.4008 - accuracy: 0.2573\n",
            "Epoch 111/150\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 1.4260 - accuracy: 0.2619\n",
            "Epoch 112/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.3996 - accuracy: 0.2681\n",
            "Epoch 113/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.3846 - accuracy: 0.2736\n",
            "Epoch 114/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.3347 - accuracy: 0.2650\n",
            "Epoch 115/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.3286 - accuracy: 0.2679\n",
            "Epoch 116/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.3807 - accuracy: 0.2659\n",
            "Epoch 117/150\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 1.3425 - accuracy: 0.2685\n",
            "Epoch 118/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.3841 - accuracy: 0.2723\n",
            "Epoch 119/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2983 - accuracy: 0.2730\n",
            "Epoch 120/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.3597 - accuracy: 0.2751\n",
            "Epoch 121/150\n",
            "49/49 [==============================] - 6s 119ms/step - loss: 1.3416 - accuracy: 0.2749\n",
            "Epoch 122/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.3208 - accuracy: 0.2792\n",
            "Epoch 123/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.3220 - accuracy: 0.2760\n",
            "Epoch 124/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.3319 - accuracy: 0.2756\n",
            "Epoch 125/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.3056 - accuracy: 0.2880\n",
            "Epoch 126/150\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 1.2988 - accuracy: 0.2812\n",
            "Epoch 127/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.3098 - accuracy: 0.2766\n",
            "Epoch 128/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2906 - accuracy: 0.2850\n",
            "Epoch 129/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.2725 - accuracy: 0.2829\n",
            "Epoch 130/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2296 - accuracy: 0.2811\n",
            "Epoch 131/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2770 - accuracy: 0.2830\n",
            "Epoch 132/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2659 - accuracy: 0.2816\n",
            "Epoch 133/150\n",
            "49/49 [==============================] - 6s 119ms/step - loss: 1.2782 - accuracy: 0.2840\n",
            "Epoch 134/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2142 - accuracy: 0.2803\n",
            "Epoch 135/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2622 - accuracy: 0.2841\n",
            "Epoch 136/150\n",
            "49/49 [==============================] - 6s 119ms/step - loss: 1.2622 - accuracy: 0.2947\n",
            "Epoch 137/150\n",
            "49/49 [==============================] - 6s 121ms/step - loss: 1.2060 - accuracy: 0.2877\n",
            "Epoch 138/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2085 - accuracy: 0.2883\n",
            "Epoch 139/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2429 - accuracy: 0.2883\n",
            "Epoch 140/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2771 - accuracy: 0.2898\n",
            "Epoch 141/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2234 - accuracy: 0.2893\n",
            "Epoch 142/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2168 - accuracy: 0.2918\n",
            "Epoch 143/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2166 - accuracy: 0.2884\n",
            "Epoch 144/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2100 - accuracy: 0.2978\n",
            "Epoch 145/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2416 - accuracy: 0.2904\n",
            "Epoch 146/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2245 - accuracy: 0.2886\n",
            "Epoch 147/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.1766 - accuracy: 0.2956\n",
            "Epoch 148/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.1838 - accuracy: 0.2950\n",
            "Epoch 149/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2100 - accuracy: 0.2932\n",
            "Epoch 150/150\n",
            "49/49 [==============================] - 6s 120ms/step - loss: 1.2200 - accuracy: 0.2952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f75b440d588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM4DUqBu5Sl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 저장\n",
        "# 단순히 가중치만 저장하는 것이 아닌 모델 전체를 저장하기 때문에\n",
        "# 다시 로드하여 학습을 이어서 할 수 있습니다.\n",
        "model_path = '/content/drive/My Drive/my_keras_model.h5'\n",
        "model.save(model_path)\n",
        "del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Eu5jQIWjn9u",
        "colab_type": "text"
      },
      "source": [
        "여기까지 모델을 학습하고 저장했습니다.\\\n",
        "다음으로 모델에 평가용 텍스트를 입력하여 출력받는 노트북을 확인해주세요\n"
      ]
    }
  ]
}